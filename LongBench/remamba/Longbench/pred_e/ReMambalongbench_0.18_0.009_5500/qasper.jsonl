{"pred": " They looked at pages from the Affective Development dataset, which was created for distant supervised emotion detection.", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null, "length": 3411}
{"pred": " The context that is used to predict intervention is the context inferred by the model.", "answers": ["the series of posts that trigger an intervention"], "all_classes": null, "length": 3732}
{"pred": " The article does not provide information about other evaluation metrics.", "answers": ["F-score, Kappa", "Unanswerable"], "all_classes": null, "length": 3544}
{"pred": " The baselines were the stacked LSTM model without cell-aware LSTM layers, the stacked LSTM model with cell-aware LSTM layers, and the model that integrated lower contexts via peephole connections.", "answers": ["(i) models that use plain stacked LSTMs, (ii) models with different INLINEFORM0, (iii) models without INLINEFORM1, (iv) models that integrate lower contexts via peephole connections"], "all_classes": null, "length": 3224}
{"pred": " Yes, jiant is compatible with models in any programming language.", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 2284}
{"pred": " Yes, the experts are comparable to real-world users.", "answers": ["No"], "all_classes": null, "length": 3843}
{"pred": " No", "answers": ["Yes", "No"], "all_classes": null, "length": 2317}
{"pred": " The article does not provide information about the datasets used for evaluation.", "answers": ["SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28", " English reviews ,  restaurant reviews from four different languages (Spanish, Turkish, Dutch, Russian)"], "all_classes": null, "length": 2720}
{"pred": " Unanswerable", "answers": ["7.36% on accuracy and 9.69% on F1 score", "it has 0.024 improvement in accuracy comparing to ELMO Only and  0.006 improvement in F1 score  comparing to ELMO Only too"], "all_classes": null, "length": 2890}
{"pred": " They use datasets with transcribed text.", "answers": ["They use text transcription.", "both"], "all_classes": null, "length": 3198}
{"pred": " The article does not provide information about clustering algorithms used.", "answers": ["CLUTO, Carrot2 Lingo", "simple clustering algorithm which uses the cosine similarity between word embeddings"], "all_classes": null, "length": 3039}
{"pred": " A neural neural network model was used.", "answers": ["Bert + Unanswerable", "CNN, BERT"], "all_classes": null, "length": 3845}
{"pred": " The pivot-based baselines are the unsupervised NMT models that leverage pivot languages to translate between source and pivot languages.", "answers": ["pivoting, pivoting$_{\\rm m}$", "firstly translates a source language into the pivot language which is later translated to the target language"], "all_classes": null, "length": 3815}
{"pred": " The article mentions that the EmotionLines dataset is used for both Friends and EmotionPush, and the EmotionPush dataset is used for the final validation.", "answers": ["Friends, EmotionPush", "EmotionLines BIBREF6"], "all_classes": null, "length": 3178}
{"pred": " The article provides several evaluation protocols for different parts of the database:\n\n- Text-dependent speaker verification: phone-level transcription, full transcription, and phoneme-level transcription\n- Text-prompted speaker verification: phone-level transcription\n- Phoneme-level transcription\n- Phoneme-level transcription with random phrase\n- Phoneme-level transcription with full transcription\n- Phoneme-level transcription with full transcription and phone-level transcription\n- Phoneme-level transcription with full transcription and phone-level transcription with full transcription\n- Phoneme-level transcription with full transcription and phone-", "answers": ["three experimental setups with different numbers of speakers in the evaluation set, three experimental setups with different number of speaker in the evaluation set are defined,  first one, respondents with at least 17 recording sessions are included to the evaluation set, respondents with 16 sessions to the development and the rest of respondents to the background set, second setup, respondents with at least 8 sessions are included to the evaluation set, respondents with 6 or 7 sessions to the development and the rest of respondents to the background set"], "all_classes": null, "length": 3880}
{"pred": " Gaussian-masked directional multi-head attention is a variant of standard multi-head attention that uses a directional Gaussian mask instead of a unidirectional mask. It is used to capture the localness information and directional information for CWS task.", "answers": ["pays attentions to adjacent characters and casts a localness relationship between the characters as a fixed Gaussian weight assuming the weight relies on the distance between characters", "Gaussian-masked directional attention can be described as a function to map queries and key-value pairs to the representation of input, Gaussian-masked directional attention expects to pay attention to the adjacent characters of each positions and cast the localness relationship between characters as a fix Gaussian weight for attention, Gaussian weight only relys on the distance between characters"], "all_classes": null, "length": 3612}
{"pred": " The system uses only monolingual data from the non-English language.", "answers": ["No data. Pretrained model is used."], "all_classes": null, "length": 3409}
{"pred": " Attention is different from alignment in cases where the attention model does not follow alignments.", "answers": ["For certain POS tags, e.g. VERB, PRON.", "most word alignments only involve one or a few words, attention can be distributed more freely"], "all_classes": null, "length": 3366}
{"pred": " They use a speech recognition system based on RNNs.", "answers": ["RNN", " Recurrent Neural Network (RNN)"], "all_classes": null, "length": 1644}
{"pred": " The baseline is the model that uses word2vec and character-level CNN.", "answers": ["CNN modelBIBREF0, Stanford CRF modelBIBREF21", "Bam et al. SVM, Ma and Hovy w/glove, Lample et al. w/fastText, Lample et al. w/word2vec"], "all_classes": null, "length": 2836}
{"pred": " This paper is published on November 1, 2019.", "answers": ["Unanswerable"], "all_classes": null, "length": 3885}
{"pred": " The article does not provide information about the number of people who participated in the evaluation study.", "answers": ["about 500", "Unanswerable"], "all_classes": null, "length": 3831}
{"pred": " The article does not provide information about the models used in the experiment.", "answers": ["linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM trained on word unigrams,  bidirectional Long Short-Term-Memory (BiLSTM),  Convolutional Neural Network (CNN) "], "all_classes": null, "length": 2250}
{"pred": " They explore various machine learning models like CNN, RNN, LSTM, and BiLSTM-CNN.", "answers": ["BiLSTM, BiLSTM-CNN, BiLSTM-CRF, BiLSTM-CNN-CRF", "BiLSTMBIBREF14, BiLSTM+CNNBIBREF20, BiLSTM+CRFBIBREF1, BiLSTM+CNN+CRFBIBREF2, CNN modelBIBREF0 and Stanford CRF modelBIBREF21"], "all_classes": null, "length": 2838}
{"pred": " Automatic discovery of word-like or phoneme-like units is performed by tokenizing the speech into a sequence of acoustic units, which are then clustered into word-like or phoneme-like units.", "answers": ["Zero Resource Toolkit (ZRTools) BIBREF7"], "all_classes": null, "length": 3381}
{"pred": " BERT-PNsmth", "answers": ["BERTbase", "BERTbase"], "all_classes": null, "length": 3852}
{"pred": " TopicRank, WINGNUS, KP-Miner, and TF INLINEFORM0 IDF.", "answers": ["Answer with content missing: (LVL1, LVL2, LVL3) \n- Stanford CoreNLP\n- Optical Character Recognition (OCR) system, ParsCIT \n- further abridge the input text from level 2 preprocessed documents to the following: title, headers, abstract, introduction, related work, background and conclusion."], "all_classes": null, "length": 1822}
{"pred": " Yes", "answers": ["Yes", "Yes"], "all_classes": null, "length": 2077}
{"pred": " The article mentions that the dataset used for summarization is the MIMIC-III dataset, which contains discharge summaries from 55,177 patients.", "answers": ["MIMIC-III", "MIMIC-III"], "all_classes": null, "length": 2992}
{"pred": " The dataset for each step of hierarchy is provided in the article.", "answers": ["Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets"], "all_classes": null, "length": 2255}
{"pred": " Attention captures useful information about the alignment between source and target words.", "answers": ["it captures other information rather than only the translational equivalent in the case of verbs", "Alignment points of the POS tags."], "all_classes": null, "length": 3372}
{"pred": " The baselines for the emotion recognition task are BERT, TFIDF, and neural-based word embeddings.", "answers": ["BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN", "bag-of-words (BOW), term frequency–inverse document frequency (TFIDF), neural-based word embedding, Logistic Regression (LR), Random Forest (RF), TextCNN BIBREF10 with initial word embedding as GloVe"], "all_classes": null, "length": 3181}
{"pred": " They look at two types of data: editor tags and Amazon search terms.", "answers": ["Unanswerable", "48,705"], "all_classes": null, "length": 3307}
{"pred": " The article does not provide information about the architecture of the model.", "answers": ["follow the architecture in berard2018end, but have 3 decoder layers like that in pino2019harnessing"], "all_classes": null, "length": 2424}
{"pred": " They used a dataset called PTB and WT-2.", "answers": [" Penn Treebank, WikiText2", "Penn Treebank (PTB) , WikiText2 (WT-2)"], "all_classes": null, "length": 3302}
{"pred": " Yes, they use graphical models.", "answers": ["No", "No"], "all_classes": null, "length": 3158}
{"pred": " Prior knowledge distillation techniques are ineffective in producing student models with vocabularies different from the original teacher models because the model parameters of the teacher model are not directly optimized for the student model. Instead, the model parameters are shared between the teacher and student models, which allows the student model to learn from the teacher model's parameters. Therefore, the student model's vocabulary size is determined by the vocabulary size of the teacher model, which is not necessarily the same as the vocabulary size of the student model.", "answers": ["While there has been existing work on reducing NLP model vocabulary sizes BIBREF15, distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes.", "distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes."], "all_classes": null, "length": 3570}
{"pred": " The baseline method used is the word2vec model.", "answers": ["using word2vec to create features that are used as input to the SVM", "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach"], "all_classes": null, "length": 3820}
{"pred": " The ancient Chinese dataset comes from the Parallel Corpus of Ancient Chinese and Modern Chinese (PACMC) which is a collection of ancient Chinese bilingual sentence pairs.", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "all_classes": null, "length": 3722}
{"pred": " No", "answers": ["No"], "all_classes": null, "length": 1561}
{"pred": " The more predictive set of features to detect fake news is the set of features that capture the sequential flow of the tweets in the accounts' timelines.", "answers": ["words embeddings, style, and morality features", "words embeddings, style, and morality features"], "all_classes": null, "length": 2091}
{"pred": " The article does not provide information about the datasets used for evaluation.", "answers": ["United Nations Parallel Corpus, IIT Bombay corpus, OpenSubtitles 2018"], "all_classes": null, "length": 3405}
{"pred": " They build word embeddings for English, French, and Spanish.", "answers": ["Unanswerable", "English"], "all_classes": null, "length": 2009}
{"pred": " Yes, the dataset is balanced between speakers of different L1s.", "answers": ["No", "No"], "all_classes": null, "length": 1899}
{"pred": " The collection of COVID-19 literature is very large, with over 2081 articles published about COVID-19, about 3600 sentences about COVID-19, and over 33,000 sentences about COVID-19.", "answers": ["45,000 scholarly articles, including over 33,000 with full text"], "all_classes": null, "length": 2150}
{"pred": " The proposed model is compared to traditional models like TF-IDF features and deep models like LSTM-self, LSTM-soft, and LSTM-self with topic-attention.", "answers": ["support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self", "support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self"], "all_classes": null, "length": 2895}
{"pred": " The article does not provide information on the number of electrodes used on the subject in EEG sessions.", "answers": ["1913 signals", "Unanswerable"], "all_classes": null, "length": 2361}
{"pred": " Macaw is a modular conversational information seeking system that consists of several modules, including a command line interface, a standard IO module, a telegram bot, a desktop app, a web app, and a wizard of oz.", "answers": ["Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation", "Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation"], "all_classes": null, "length": 1701}
{"pred": " No, their indexing-based method is specific to the Wikipedia corpus.", "answers": ["Unanswerable"], "all_classes": null, "length": 1913}
{"pred": " Persian", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 3794}
{"pred": " The article does not provide information about the datasets used for experiments.", "answers": ["SQuAD", "SQuAD"], "all_classes": null, "length": 3757}
{"pred": " SemEval 2010 task 8 data set", "answers": ["relation classification dataset of the SemEval 2010 task 8", "SemEval 2010 task 8 BIBREF8"], "all_classes": null, "length": 2393}
{"pred": " The corpora they trained ELMo on were the English Wikipedia dump from February 2017 and the Russian Wikipedia dump from December 2018.", "answers": ["2174000000, 989000000", "2174 million tokens for English and 989 million tokens for Russian"], "all_classes": null, "length": 2958}
{"pred": " Yes, the qualitative experiments are performed on benchmark datasets.", "answers": ["Spearman correlation values of GM_KL model evaluated on the benchmark word similarity datasets.\nEvaluation results of GM_KL model on the entailment datasets such as entailment pairs dataset created from WordNet, crowdsourced dataset of 79 semantic relations labelled as entailed or not and annotated distributionally similar nouns dataset.", "Given a query word and component id, the set of nearest neighbours along with their respective component ids are listed"], "all_classes": null, "length": 2220}
{"pred": " The method improvements of F1 for paraphrase identification are:\n\n1. Using dice loss instead of cross-entropy loss.\n2. Using weighted cross-entropy loss.\n3. Using a weighted training objective.\n4. Using a hard negative mining strategy.\n5. Using a self-adversarial training strategy.\n\nThe above improvements aim to improve the F1 score by making the model more difficult to classify negative examples as negative, while making positive examples more likely to be classified as positive.", "answers": ["Using DSC loss improves the F1 score by +0.58 for MRPC and +0.73 for QQP", "+0.58"], "all_classes": null, "length": 3566}
{"pred": " They calculate variance from the model outputs by marginalizing over the most likely labelings.", "answers": ["reducing the variance of an estimator,  EGL method in BIBREF3 is almost the same as Eq. ( EQREF8 ), except the gradient's norm is not squared in BIBREF3", " Fisher Information Ratio"], "all_classes": null, "length": 1671}
{"pred": " The encoder has a character-level LSTM encoder.", "answers": ["LSTM", "LSTM"], "all_classes": null, "length": 2289}
{"pred": " The ReviewQA dataset contains 8 tasks, each of which requires a different kind of question. These questions are related to the aspects of the document mentioned in the text. Some questions are related to the aspect that is mentioned in the text immediately, while others are related to the aspect that has to be predicted. Therefore, the questions in the ReviewQA dataset are unanswerable.", "answers": ["These 8 tasks require different competencies and a different level of understanding of the document to be well answered"], "all_classes": null, "length": 3817}
{"pred": " No, other baselines were not tested to compare with the neural baseline.", "answers": ["SVM, No-Answer Baseline (NA) , Word Count Baseline, Human Performance", "No-Answer Baseline (NA), Word Count Baseline, Human Performance"], "all_classes": null, "length": 3855}
{"pred": " There are 53 documents in the new corpus.", "answers": ["53 documents", "53 documents"], "all_classes": null, "length": 2667}
{"pred": " They get the recipes from a user-generated dataset.", "answers": ["from Food.com"], "all_classes": null, "length": 2649}
{"pred": " They evaluate their resulting word embeddings by comparing them to word vectors generated by fastText.", "answers": ["We also evaluate all five models on downstream tasks from the VecEval suite BIBREF13 , using only the tasks for which training and evaluation data is freely available: chunking, sentiment and question classification, and natural language identification (NLI). The default settings from the suite are used, but we run only the fixed settings, where the embeddings themselves are not tunable parameters of the models, forcing the system to use only the information already in the embeddings."], "all_classes": null, "length": 2083}
{"pred": " 10 other phenotypes that are annotated are:\n\n1. Age\n2. Sex\n3. Race\n4. Length of stay\n5. Length of stay in ICU\n6. Length of stay in hospital\n7. Length of stay in ICU after discharge\n8. Length of stay in hospital after discharge\n9. Length of stay in ICU after discharge\n10. Length of stay in hospital after discharge\n11. Length of stay in ICU after discharge\n12. Length of stay in hospital after discharge\n13. Length of stay in ICU after discharge\n14. Length of stay in hospital after discharge\n15. Length of", "answers": ["Adv. Heart Disease, Adv. Lung Disease, Alcohol Abuse, Chronic Neurologic Dystrophies, Dementia, Depression, Developmental Delay, Obesity, Psychiatric disorders and Substance Abuse"], "all_classes": null, "length": 1651}
{"pred": " Unanswerable", "answers": ["204 tokens", "Most texts, however, range roughly from 150 to 250 tokens."], "all_classes": null, "length": 1898}
{"pred": " Patterns are extracted from the input sentences in the training data.", "answers": ["(VVD shop_VV0 II, VVD shopping_VVG II)", "patterns for generating all types of errors"], "all_classes": null, "length": 2133}
{"pred": " Yes", "answers": ["No", "No"], "all_classes": null, "length": 3974}
{"pred": " The Random Kitchen Sink approach is a machine learning technique that involves using a combination of features extracted from the data. It is a unsupervised approach that aims to improve the classification performance by exploring the potential of the data.", "answers": ["Random Kitchen Sink method uses a kernel function to map data vectors to a space where linear separation is possible.", "explicitly maps data vectors to a space where linear separation is possible, RKS method provides an approximate kernel function via explicit mapping"], "all_classes": null, "length": 2361}
{"pred": " They compare their model to a Big Transformer model and a bi-directional model.", "answers": ["BIBREF11 , BIBREF26 "], "all_classes": null, "length": 1912}
{"pred": " Their results are on both datasets.", "answers": ["Combining  pattern based and Machine translation approaches gave the best overall F0.5 scores. It was 49.11 for FCE dataset  , 21.87 for the first annotation of  CoNLL-14, and 30.13 for the second annotation of CoNLL-14. "], "all_classes": null, "length": 2164}
{"pred": " They test their method on the task of predicting hashtags for a post from its latent representation.", "answers": ["None"], "all_classes": null, "length": 2473}
{"pred": " Experts were recruited from the privacy community.", "answers": ["Individuals with legal training", "Yes"], "all_classes": null, "length": 3846}
{"pred": " Word segmentation in Vietnamese has been approached using several approaches, including statistical, linguistic, and machine learning approaches. Statistical approaches include Hidden Markov Models (HMMs) and Maximum Matching (MM) while linguistic approaches include n-gram models, context-based features, and linguistics knowledge. Machine learning approaches include Support Vector Machines (SVMs) and Conditional Random Fields (CRFs).", "answers": ["Maximum Entropy, Weighted Finite State Transducer (WFST),  support vector machines (SVM), conditional random fields (CRF)", "Maximum matching, Hidden Markov model , Maximum Entropy, Conditional Random Fields , Support Vector Machines"], "all_classes": null, "length": 3471}
{"pred": " The article mentions that three named entity recognition models were evaluated: Stanford NER, spaCy 2.0, and a recurrent model with a CRF layer.", "answers": ["Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer", "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"], "all_classes": null, "length": 2759}
{"pred": " The datasets used to evaluate this paper are WN18 and FB15K.", "answers": ["WordNet BIBREF0, Freebase BIBREF1, WN18 (a subset of WordNet) BIBREF24 , FB15K (a subset of Freebase) BIBREF2"], "all_classes": null, "length": 3367}
{"pred": " The baseline model used is a multi-attention model with a projected layer.", "answers": [" LastStateRNN, AvgRNN, AttentionRNN", "LastStateRNN, AvgRNN, AttentionRNN "], "all_classes": null, "length": 2823}
{"pred": " Cyberbullying topics addressed in the article include:\n\n- Formspring\n- Twitter\n- Wikipedia\n- Personal attacks\n- Anonymous posts\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Overfitting\n- Over", "answers": ["personal attack, racism, and sexism", "racism, sexism, personal attack, not specifically about any single topic"], "all_classes": null, "length": 3244}
{"pred": " Yes", "answers": ["Yes", "Yes"], "all_classes": null, "length": 3634}
{"pred": " The article does not provide information about the dataset used for this study.", "answers": ["BIBREF12 , BIBREF13", "an existing, annotated Twitter dataset that was constructed based on a hierarchical model of depression-related symptoms BIBREF12 , BIBREF13"], "all_classes": null, "length": 1939}
{"pred": " The article discusses the similarity between languages, but does not provide a specific answer to the question.", "answers": ["Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "The Nguni languages are similar to each other, The same is true of the Sotho languages"], "all_classes": null, "length": 1877}
{"pred": " The sentiment analysis dataset used is the IMDb dataset.", "answers": ["IMDb dataset of movie reviews", "IMDb"], "all_classes": null, "length": 2327}
{"pred": " Their system's performance was unanswerable.", "answers": ["accuracy and F1-score of 89.6% and 89.2%, respectively", "accuracy and F1-score of 89.6% and 89.2%, respectively"], "all_classes": null, "length": 3313}
{"pred": " None of the baseline approaches mentioned in the article outperform AEM.", "answers": ["K-means, LEM BIBREF13, DPEMM BIBREF14", "K-means, LEM, DPEMM"], "all_classes": null, "length": 3841}
{"pred": " English, Spanish, French, German, Italian, Russian, Mandarin, and Korean.", "answers": ["English, German, Spanish, Mandarin, Polish, Russian, Korean and Serbian", "English (Edinburgh), German (Berlin), Spanish (Madrid), Mandarin (Taipei), Polish (Warsaw), Russian (Moscow), Korean (Seoul), and Serbian (Belgrade)"], "all_classes": null, "length": 2754}
{"pred": " The article does not provide information about the sources of the datasets.", "answers": ["rupnik2016news", "rupnik2016news, Deutsche Welle's news website"], "all_classes": null, "length": 3160}
{"pred": " Yes, the lexicon is the same for all languages.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 1868}
{"pred": " SBERT, InferSent, Universal Sentence Encoder, and RoBERTa.", "answers": ["GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent", "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder."], "all_classes": null, "length": 3862}
{"pred": " Transfer learning tasks are evaluated on the STS benchmark dataset.", "answers": ["MR, CR, SUBJ, MPQA, SST, TREC, MRPC", "MR: Sentiment prediction for movie reviews snippets on a five start scale BIBREF25.\n\nCR: Sentiment prediction of customer product reviews BIBREF26.\n\nSUBJ: Subjectivity prediction of sentences from movie reviews and plot summaries BIBREF27.\n\nMPQA: Phrase level opinion polarity classification from newswire BIBREF28.\n\nSST: Stanford Sentiment Treebank with binary labels BIBREF29.\n\nTREC: Fine grained question-type classification from TREC BIBREF30.\n\nMRPC: Microsoft Research Paraphrase Corpus from parallel news sources BIBREF31.", "Semantic Textual Similarity, sentiment prediction, subjectivity prediction, phrase level opinion polarity classification, Stanford Sentiment Treebank, fine grained question-type classification."], "all_classes": null, "length": 3861}
{"pred": " The vocabulary size is not provided in the article.", "answers": ["33,663", "33,663 distinct review keywords "], "all_classes": null, "length": 3305}
{"pred": " Additional features include character-level representations, context tweets, and context tweets with the use of neural networks.", "answers": ["using tweets that one has replied or quoted to as contextual information", "text sequences of context tweets"], "all_classes": null, "length": 2060}
{"pred": " Yes, they evaluate their learned representations on downstream tasks.", "answers": ["No", "No"], "all_classes": null, "length": 1906}
{"pred": " Yes", "answers": ["No", "No"], "all_classes": null, "length": 1443}
{"pred": " Best performing model among author's submissions is LSTM-CRF with BERTSentEmb, which achieved 3rd place in FLC task with a score of 0.673.", "answers": ["For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."], "all_classes": null, "length": 1541}
{"pred": " The task is based on a diachronic corpus of German BIBREF0.", "answers": ["DTA18, DTA19", "Diachronic Usage Relatedness (DURel) gold standard data set"], "all_classes": null, "length": 1908}
{"pred": " The TweetQA dataset contains 10,898 questions and answers from news media, with a total of 13,766 question-answer pairs.", "answers": ["13,757", "10,898 articles, 17,794 tweets, and 13,757 crowdsourced question-answer pairs"], "all_classes": null, "length": 3704}
{"pred": " KNN, RF, SVM, and MLP", "answers": ["KNN\nRF\nSVM\nMLP", " K Nearest Neighbors (KNN), Random Forest (RF), Support Vector Machine (SVM), Multi-layer Perceptron (MLP)"], "all_classes": null, "length": 1639}
{"pred": " They use a new context representation that is based on convolutions and recurrent neural networks.", "answers": ["They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."], "all_classes": null, "length": 2435}
{"pred": " Multi-granularity neural architecture design involves the use of multiple neural architectures, such as LSTM-CRF, CNN, and BERT, to perform different tasks like sentence-level propaganda detection, fragment-level propaganda detection, and sentence-level propaganda detection. Multi-tasking neural architecture design involves the use of a multi-grain architecture with different neural architectures for different tasks, like multi-grain LSTM-CRF and multi-grain CNN.", "answers": ["An output layer for each task", "Multi-tasking is addressed by neural sequence tagger based on LSTM-CRF and linguistic features, while multi-granularity is addressed by ensemble of LSTM-CRF and BERT."], "all_classes": null, "length": 1514}
{"pred": " The CORD-19 dataset is a collection of COVID-19 literature, which includes over 2081 articles and about 33,000 sentences.", "answers": ["which contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses", "contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses"], "all_classes": null, "length": 2156}
{"pred": " The real-life dataset is not provided in the article.", "answers": ["26972", "26972 sentences"], "all_classes": null, "length": 3040}
{"pred": " The state of the art methods for grammar induction are:\n\n- Neural PCFGs (NPFGs)\n- Compound PCFGs (CPFGs)\n- RNNGs\n- LSTM-based RNNG\n- LSTM-based RNNG with RNNG-induced trees\n- LSTM-based RNNG with RNNG-induced trees with RNNG-induced trees with RNNG-induced trees with RNNG-induced trees with RNNG-induced trees with RNNG-induced trees with RNNG-induced trees with RNNG-induced", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 2533}
{"pred": " Backoff strategies work by replacing the UNK token with a fixed backoff token, which is then used as an input to the downstream classifier. This strategy is effective in reducing the number of unique output words, making the model more robust to character-level attacks.", "answers": ["In pass-through, the recognizer passes on the possibly misspelled word, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Pass-through passes the possibly misspelled word as is, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Backoff to \"a\" when an UNK-predicted word is encountered, backoff to a more generic word recognition model when the model predicts UNK"], "all_classes": null, "length": 4210}
{"pred": " A user simulator is used to learn behavior.", "answers": ["DSTC2", "The manual transcriptions of the DSTC2 training set "], "all_classes": null, "length": 4820}
{"pred": " The metrics used for evaluation are BLEU, ROUGE, and NIST.", "answers": ["BLEU-4, NIST-4, ROUGE-4", "BLEU-4, NIST-4, ROUGE-4"], "all_classes": null, "length": 4460}
{"pred": " The state-of-the-art models for judgment prediction in the legal area are proposed in the article.", "answers": ["SVM , CNN , GRU , CNN/GRU+law, r-net , AoA ", "SVM with lexical features in accordance with previous works BIBREF16 , BIBREF17 , BIBREF1 , BIBREF15 , BIBREF4, attention-based method BIBREF3 and other methods we deem important, some off-the-shelf RC models, including r-net BIBREF5 and AoA BIBREF6 , which are the leading models on SQuAD leaderboard"], "all_classes": null, "length": 4106}
{"pred": " linguistics features used are:\n- morphological patterns\n- syntactic patterns\n- surface features\n- morphological patterns\n- syntactic patterns\n- surface features\n- morphological patterns\n- syntactic patterns\n- surface features\n- morphological patterns\n- syntactic patterns\n- surface features\n- morphological patterns\n- syntactic patterns\n- surface features\n- morphological patterns\n- syntactic patterns\n- surface features\n- morphological patterns\n- syntactic patterns\n- surface features\n- morphological patterns\n- syntactic patterns\n- surface features\n- morphological patterns\n- syntactic patterns\n- surface features\n- morphological patterns\n", "answers": ["POS, gender/number and stem POS"], "all_classes": null, "length": 4719}
{"pred": " Along the dimension of relatedness.", "answers": ["dimension corresponding to the concept that the particular word belongs to"], "all_classes": null, "length": 6182}
{"pred": " English", "answers": ["English , German, French"], "all_classes": null, "length": 4173}
{"pred": " No, their framework does not automatically optimize for hyperparameters.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 4465}
{"pred": " mainstream news and disinformation news", "answers": ["mainstream news and disinformation", "mainstream and disinformation news"], "all_classes": null, "length": 4856}
{"pred": " Experiments are performed on text-based games.", "answers": ["CoinCollector , CookingWorld ", "CoinCollector, CookingWorld"], "all_classes": null, "length": 4924}
{"pred": " Two metrics are proposed: R@10/50 and F INLINEFORM0 @ R@10/50.", "answers": ["average unique predictions, randomly sample 2000 decoder hidden states at INLINEFORM4 steps following a delimiter ( INLINEFORM5 ) and apply an unsupervised clustering method (t-SNE BIBREF35 )"], "all_classes": null, "length": 4581}
{"pred": " Their model captures biases from data collection and rules of annotation.", "answers": ["Data annotation biases where tweet containing disrespectful words are annotated as hate or offensive without any presumption about the social context of tweeters"], "all_classes": null, "length": 4111}
{"pred": " Future possible improvements are listed as:\n\n- Improvements in the encoder model to better capture the structure of the input data.\n- Improvements in the hierarchical attention mechanism to better guide the decoding process.\n- Improvements in the model architecture to better model the data structure.\n- Improvements in the model training to better optimize the model.\n\nAnswer: Improvements in the model architecture to better model the data structure.", "answers": ["rther constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions", "to further constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions"], "all_classes": null, "length": 4704}
{"pred": " The additive modification to the objective function is the introduction of an additional cost term to the optimization routine that favors a subset of words along the same dimension.", "answers": ["The cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function. . Each embedding vector dimension is first associated with a concept. For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to,", "An additive term added to the cost function for any one of the words of concept word-groups"], "all_classes": null, "length": 6244}
{"pred": " No, the article reports results on both English and French data.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 7837}
{"pred": " Their document-level encoder is novel as it uses pretrained document representations instead of token-level representations.", "answers": ["Bert model have a maximum length of 512; we overcome this limitation by adding more position embeddings, we insert external [cls] tokens at the start of each sentence, and each [cls] symbol collects features for the sentence preceding it, document representations are learned hierarchically"], "all_classes": null, "length": 4404}
{"pred": " Their model improves interpretability by learning a sparse attention distribution, which is unanswerable.", "answers": ["the attention heads in the proposed adaptively sparse Transformer can specialize more and with higher confidence", "We introduce sparse attention into the Transformer architecture"], "all_classes": null, "length": 4902}
{"pred": " Unanswerable", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 5331}
{"pred": " unanswerable", "answers": ["22,880 users", "20,000"], "all_classes": null, "length": 4160}
{"pred": " An instance is a sentence.", "answers": ["sentence"], "all_classes": null, "length": 4369}
{"pred": " Unanswerable", "answers": ["The Conversations Gone Awry dataset is labelled as either containing a personal attack from withint (i.e. hostile behavior by one user in the conversation directed towards another) or remaining civil throughout. The Reddit Change My View dataset is labelled with whether or not a coversation eventually had a comment removed by a moderator for violation of Rule 2: \"Don't be rude or hostile to others users.\""], "all_classes": null, "length": 4779}
{"pred": " The article does not provide information about the datasets used in the experiments.", "answers": ["build a new one, collect INLINEFORM0 cases from China Judgments Online"], "all_classes": null, "length": 4109}
{"pred": " The model is trained to translate from a source language to a target language, and the style transfer task is to translate from a source style to a target style. Therefore, the model's output is a single sentence that is both in the source style and the target style. Therefore, the model's output is a single sentence that is both in the source style and the target style. Therefore, the model's output is a single sentence that is both in the source style and the target style. Therefore, the model's output is a single sentence that is both in the source style and the target style. Therefore, the model's output is a", "answers": ["Unanswerable"], "all_classes": null, "length": 4572}
{"pred": " This method improves over the best performing state-of-the-art by leveraging the sensationalism score as a reward for reinforcement learning.", "answers": ["absolute improvement of 18.2% over the Pointer-Gen baseline"], "all_classes": null, "length": 4091}
{"pred": " The human judgements were assembled by collecting the scores of the translations from the human evaluators.", "answers": ["50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale.", "adequacy, precision and ranking values"], "all_classes": null, "length": 5344}
{"pred": " They use a deep learning model to predict the quality of academic papers.", "answers": ["visual model is based on fine-tuning an Inception V3 model BIBREF1 over visual renderings of documents, while our textual model is based on a hierarchical biLSTM. We further combine the two into a joint model. , neural network models", "Inception V3, biLSTM"], "all_classes": null, "length": 4217}
{"pred": " The baseline was a strong NMT model trained on the concatenation of all the in-domain parallel corpora for the translation task.", "answers": ["pivot-based translation relying on a helping language BIBREF10, nduction of phrase tables from monolingual data BIBREF14 , attentional RNN-based model (RNMT) BIBREF2, Transformer model BIBREF18, bi-directional model BIBREF11, multi-to-multi (M2M) model BIBREF8, back-translation BIBREF17", "M2M Transformer"], "all_classes": null, "length": 4542}
{"pred": " The global network features which quantify different aspects of the sharing process are:\n\n1. Retweet (RT) count\n2. Retweet (RT) rate\n3. Quote (Q) count\n4. Quote (Q) rate\n5. Mention (M) count\n6. Mention (M) rate\n7. Quote-Retweet (QR) count\n8. Quote-Retweet (QR) rate\n9. Quote-Mention (QM) count\n10. Quote-Mention (QM) rate\n11. Quote-Retweet-", "answers": ["Number of Strongly Connected Components (SCC), Size of the Largest Strongly Connected Component (LSCC), Number of Weakly Connected Components (WCC), Size of the Largest Weakly Connected Component (LWCC), Diameter of the Largest Weakly Connected Component (DWCC), Average Clustering Coefficient (CC), Main K-core Number (KC), Density (d)"], "all_classes": null, "length": 4906}
{"pred": " The baseline is the untrained model that does not use pretrained embeddings.", "answers": ["QA PGNet, Multi-decoder QA PGNet with lookup table embedding", "QA PGNet and Multi-decoder QA PGNet"], "all_classes": null, "length": 4600}
{"pred": " KB relation detection", "answers": ["answer questions by obtaining information from KB tuples ", "hierarchical matching between questions and relations with residual learning"], "all_classes": null, "length": 4527}
{"pred": " RL", "answers": ["BIBREF7", " reward learning algorithm BIBREF7"], "all_classes": null, "length": 4841}
{"pred": " They used the BioASQ dataset.", "answers": ["BioASQ  dataset", "A dataset provided by BioASQ consisting of questions, gold standard documents, snippets, concepts  and ideal and ideal answers."], "all_classes": null, "length": 6810}
{"pred": " Manual Pyramid scores are used to compare the quality of the summaries.", "answers": [" higher tiers of the pyramid", "following the pyramid framework, we design an annotation scheme"], "all_classes": null, "length": 4771}
{"pred": " Their models calculate the importance of words by integrating gradients.", "answers": ["Given the contribution matrix, we can obtain the word importance of each input word to the entire output sentence. ", "They compute the gradient of the output at each time step with respect to the input words to decide the importance."], "all_classes": null, "length": 4253}
{"pred": " The state of the art models for sarcasm detection are CNN-SVM, CNN-RNN, and CNN-LSTM.", "answers": ["BIBREF9 , BIBREF8 ", "BIBREF9 , BIBREF8"], "all_classes": null, "length": 4855}
{"pred": " Yes, classification performance is improved in experiments for low data regime and class-imbalance problems.", "answers": ["Low data: SST-5, TREC, IMDB around 1-2 accuracy points better than baseline\nImbalanced labels: the improvement over the base model increases as the data gets more imbalanced, ranging from around 6 accuracy points on 100:1000 to over 20 accuracy points on 20:1000"], "all_classes": null, "length": 4880}
{"pred": " Reading Comprehension", "answers": ["MULTIPLE CHOICE QUESTION ANSWERING", "multiple-choice"], "all_classes": null, "length": 6396}
{"pred": " The article mentions that the datasets used for hate speech detection are Waseem and Davidson.", "answers": ["Waseem-dataset, Davidson-dataset,", "Waseem and Hovey BIBREF5, Davidson et al. BIBREF9"], "all_classes": null, "length": 4090}
{"pred": " They test their word importance approach on three model architectures: Transformer, RNN-Search, and Attention.", "answers": [" Transformer BIBREF1 model and the conventional RNN-Search model BIBREF0", "Transformer, RNN-Search model"], "all_classes": null, "length": 4240}
{"pred": " Keyphrase diversity is measured by the number of unique phrases generated by the model.", "answers": ["average unique predictions, illustrate the difference of predictions between our proposed models, we show an example chosen from the KP20k validation set"], "all_classes": null, "length": 4576}
{"pred": " Yes", "answers": ["Answer with content missing: (Evaluation Metrics section) Precision, Recall, F1-scores, Strict match, METEOR, ROUGE-2"], "all_classes": null, "length": 4263}
{"pred": " They compared their model with a 9-layers unidirectional LSTM model trained with CE loss.", "answers": ["Unidirectional LSTM networks with 2, 6, 7, 8, and  9 layers."], "all_classes": null, "length": 4286}
{"pred": " Professional translation introduces the artifacts.", "answers": ["Yes"], "all_classes": null, "length": 4073}
{"pred": " KAR is a model that uses general knowledge to enhance the performance of an MRC model.", "answers": ["Lexicon Embedding Layer, Context Embedding Layer, Coarse Memory Layer, Refined Memory Layer, Answer Span Prediction Layer"], "all_classes": null, "length": 4133}
{"pred": " Future work will explore more human-labeled Chinese sensational headlines and evaluate the effectiveness of the proposed model.", "answers": ["ethical questions about generating sensational headlines, which can be further explored,  improving the sensationalism scorer, investigating the applications of dynamic balancing methods between RL and MLE"], "all_classes": null, "length": 4104}
{"pred": " The dataset models character's profiles by collecting information on various characters from TV shows, movies, and games.", "answers": ["attributes are determined by human viewers and their impressions of the characters, and are correlated with human-like characteristics"], "all_classes": null, "length": 5136}
{"pred": " Reuters-8 dataset", "answers": ["Reuters-8 dataset without stop words", "The Reuters-8 dataset (with stop words removed)"], "all_classes": null, "length": 5147}
{"pred": " The accuracy merits of the approach are demonstrated by the significant improvement in model performance when using the proposed human-AI loop approach.", "answers": ["significant improvements clearly demonstrate that our approach is effective at improving model performance", "By evaluating the performance of the approach using accuracy and AUC"], "all_classes": null, "length": 4489}
{"pred": " The authors present evidence that the model can capture some biases in data annotation and collection by examining the effect of different fine-tuning strategies on the performance of a hate speech detection system.", "answers": ["The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate"], "all_classes": null, "length": 4119}
{"pred": " On the SimpleQuestions BIBREF4 and WebQSP BIBREF20 benchmarks.", "answers": ["SimpleQuestions, WebQSP", "WebQSP, SimpleQuestions"], "all_classes": null, "length": 4524}
{"pred": " The model is more reliable for grammatical errors, spelling errors, and lexical errors.\n\nQuestion: How does the model perform on different style transfer tasks?\n\nAnswer: The model performs well on informal style transfer, but struggles with formal style transfer.\n\nQuestion: How does the model perform on different error types?\n\nAnswer: The model performs well on spelling and grammar errors, but struggles with lexical errors.\n\nQuestion: How does the model perform on different style transfer tasks?\n\nAnswer: The model performs well on informal style transfer, but struggles on formal style transfer.\n\nQuestion: How", "answers": ["grammatical, spelling and word order errors", "spelling, word order and grammatical errors"], "all_classes": null, "length": 4579}
{"pred": " The authors used a combination of pre-training and reinforcement learning to generate ironic sentences from non-ironic sentences. They first trained a language model to generate non-ironic sentences, then used reinforcement learning to generate ironic sentences from non-ironic sentences.", "answers": ["They developed a classifier to find ironic sentences in twitter data", "by crawling"], "all_classes": null, "length": 4599}
{"pred": " They mean the global context of each topic and the local context of each sentence within that topic.", "answers": ["global (the whole document), local context (e.g., the section/topic)", "global (the whole document) and the local context (e.g., the section/topic) "], "all_classes": null, "length": 4287}
{"pred": " Knowledge Base Question Answering", "answers": ["Knowledge Base Question Answering", "Knowledge Base Question Answering "], "all_classes": null, "length": 4521}
{"pred": " They utilize LDA and Gibbs sampling to evaluate ISWC and WWW publications.", "answers": ["the LDA approaches to recommendation systems and given the importance of research, we have studied recent impressive articles on this subject and presented a taxonomy of recommendation systems based on LDA of the recent research, we evaluated ISWC and WWW conferences articles from DBLP website and used the Gibbs sampling algorithm as an evaluation parameter", "discover the trends of the topics and find relationship between LDA topics and paper features and generate trust tags,  learn a LDA model with 100 topics; $\\alpha =0.01$, $\\beta = 0.01$ and using Gibbs sampling as a parameter estimation"], "all_classes": null, "length": 4322}
{"pred": " Yes", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4127}
{"pred": " Analyzed corpora contain a significant gender imbalance.", "answers": ["Women represent 33.16% of the speakers"], "all_classes": null, "length": 4055}
{"pred": " The baseline model was BERT-Base masked language model from BERT-Base Wikipedia, unanswerable.", "answers": ["by answering always YES (in batch 2 and 3) "], "all_classes": null, "length": 6817}
{"pred": " The highest recall score for the model was 0.9.", "answers": ["0.7033", "0.7033"], "all_classes": null, "length": 6810}
{"pred": " The evaluation criteria and metrics used to evaluate the generated text were:\n\n1. Length: Length of the generated text compared to the length of the input data.\n2. Word error rate: Percentage of ungrammatical words in the generated text compared to the input data.\n3. Factual correctness: Percentage of factual errors in the generated text compared to the input data.\n4. Fluency: Readability of the generated text compared to the input data.\n5. Acceptability: Acceptability of the generated text based on the domain expertise of the journalists.\n\nAnswer: Length, word error rate, factual", "answers": ["BLEU , NIST , METEOR , ROUGE-L, CIDEr , evaluation script, automatic evaluation, human evaluation, minimum edit evaluation, word error rate (WER), factual errors and their types, fluency issues, acceptability of the output for production use in a news agency", "BLEU, NIST, METEOR, ROUGE-L, CIDEr"], "all_classes": null, "length": 4738}
{"pred": " They used a machine learning model based on text-based features.", "answers": ["AllWords model by counting the frequencies of all the remaining words and training a multinomial Naive Bayes classifier"], "all_classes": null, "length": 4177}
{"pred": " The article mentions that the datasets used for event detection are CyberAttack and PoliticianDeath.", "answers": ["Tweets related to CyberAttack and tweets related to PoliticianDeath", "cyber security (CyberAttack), death of politicians (PoliticianDeath)"], "all_classes": null, "length": 4481}
{"pred": " RQE is a machine learning and deep learning method for question answering.", "answers": ["Logistic Regression, neural networks"], "all_classes": null, "length": 7257}
{"pred": " The strong baseline is the model that uses a single-layer encoder with a single-layer decoder.", "answers": ["Conditional Copy (CC) model ", "delayed copy model (DEL),  template system (TEM), conditional copy (CC), NCP+CC (NCP)"], "all_classes": null, "length": 4746}
{"pred": " The invertibility condition is that the joint distribution of data and latent variables is invertible.", "answers": ["The neural projector must be invertible.", "we constrain our neural projector with two requirements: (1) INLINEFORM0 and (2) INLINEFORM1 exists"], "all_classes": null, "length": 4323}
{"pred": " The article does not provide information about the type of classifiers used.", "answers": ["probabilistic model", "Logistic Regression, Multilayer Perceptron"], "all_classes": null, "length": 4475}
{"pred": " The real-world civil case dataset is a real-world dataset for experiments, and it is not provided in the article.", "answers": ["100 000 documents", " INLINEFORM1 cases"], "all_classes": null, "length": 4104}
{"pred": " The data was collected by asking workers to write questions and answers based on a scenario.", "answers": ["The data was collected using 3 components: describe a series of pilot studies that were conducted to collect commonsense inference questions, then discuss the resulting data collection of questions, texts and answers via crowdsourcing on Amazon Mechanical Turk and gives information about some necessary postprocessing steps and the dataset validation."], "all_classes": null, "length": 4536}
{"pred": " tokenization, word segmentation, subword segmentation, back translation, mix-source, synthetic data, and data augmentation.", "answers": ["Back Translation, Mix-Source Approach", "data augmentation"], "all_classes": null, "length": 4123}
{"pred": " The difference in performance between proposed model and baselines is significant.", "answers": ["Metric difference between Aloha and best baseline score:\nHits@1/20: +0.061 (0.3642 vs 0.3032)\nMRR: +0.0572(0.5114 vs 0.4542)\nF1: -0.0484 (0.3901 vs 0.4385)\nBLEU: +0.0474 (0.2867 vs 0.2393)"], "all_classes": null, "length": 5151}
{"pred": " Arabic offensive language is characterized by its use of vulgarity, hate speech, and insults.", "answers": ["Frequent use of direct animal name calling, using simile and metaphors, through indirect speech like sarcasm, wishing evil to others, name alteration, societal stratification, immoral behavior and sexually related uses.", "Direct name calling, Simile and metaphor, Indirect speech, Wishing Evil, Name alteration, Societal stratification, Immoral behavior, Sexually related"], "all_classes": null, "length": 4566}
{"pred": " The authors show that their learned policy generalize better to unseen games by comparing it to a baseline that uses a count-based reward in phase 1 and a count-based reward in phase 2.", "answers": ["promising results by solving almost half of the unseen games, most of the lost games are in the hardest set, where a very long sequence of actions is required for winning the game"], "all_classes": null, "length": 4964}
{"pred": " Analyze the gender bias in the news broadcast domain and Anchor role to understand the impact of gender representation in training data on ASR performance.", "answers": ["create fair systems", " broadcast recordings are also a valuable source of data for the speech processing community, recent works uncovering gender bias in several natural language processing (NLP) tools"], "all_classes": null, "length": 4063}
{"pred": " They build a predictive model based on linguistic features of dogmatism.", "answers": ["logistic regression models", "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."], "all_classes": null, "length": 4208}
{"pred": " Yes, they released their data set of academic papers.", "answers": ["No", "Unanswerable"], "all_classes": null, "length": 4181}
{"pred": " The state-of-the-art system is the Message Passing Attention network for Document understanding (MPAD).", "answers": ["doc2vec , CNN, DAN, Tree-LSTM, DRNN, LSTMN, C-LSTM, SPGK, WMD, S-WMD, Semantic-CNN, LSTM-GRNN, HN-ATT"], "all_classes": null, "length": 4169}
{"pred": " They measure which words are under-translated by NMT models by calculating the importance of words based on their gradients.", "answers": ["They measured the under-translated words with low word importance score as calculated by Attribution.\nmethod", "we ask ten human annotators to manually label the under-translated input words, and at least two annotators label each input-hypothesis pair"], "all_classes": null, "length": 4246}
{"pred": " Two datasets are applied to the model: the first dataset is for the task of forecasting derailment, while the second is for the task of detecting whether a conversation actually derails.", "answers": [" `Conversations Gone Awry' dataset, subreddit ChangeMyView", "An expanded version of the existing 'Conversations Gone Awry' dataset and the ChangeMyView dataset, a subreddit whose only annotation is whether the conversation required action by the Reddit moderators. "], "all_classes": null, "length": 4718}
{"pred": " Yes, they collected their own data.", "answers": ["No"], "all_classes": null, "length": 4117}
{"pred": " The article does not provide information about the dataset used.", "answers": ["Europarl corpus , WMT newstest 2014, News-Commentary-11, Wikipedia from WMT 2014, Multi-UN, EU-Bookshop, Rapid, Common-Crawl (WMT 2017)", "Europarl tests from 2006, 2007, 2008; WMT newstest 2014."], "all_classes": null, "length": 4184}
{"pred": " Yes, they collected the two datasets.", "answers": ["No", "No"], "all_classes": null, "length": 4484}
{"pred": " A second order co-occurrence matrix is a matrix that contains information about the similarity between pairs of words. It is a special case of a second order vector, which is a vector that contains information about the similarity between pairs of words.", "answers": ["frequencies of the other words which occur with both of them (i.e., second order co–occurrences)", "The matrix containing co-occurrences of the words which occur with the both words of every given pair of words."], "all_classes": null, "length": 4271}
{"pred": " Yes, the evaluation metrics are reported.", "answers": ["precision, recall, F1 and accuracy", "precision, recall, F1 , accuracy "], "all_classes": null, "length": 4101}
{"pred": " Yes, the authors report results only on English data.", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 4770}
{"pred": " They match annotators to instances by predicting annotation difficulty.", "answers": ["Annotations from experts are used if they have already been collected."], "all_classes": null, "length": 4377}
{"pred": " The dataset consists of 2,100 questions and answers.", "answers": ["13,939"], "all_classes": null, "length": 4489}
{"pred": " Yes, the data is de-identified.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4592}
{"pred": " No, they do not use pretrained embeddings.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4457}
{"pred": " ROGUE-1, ROGUE-2, ROGUE-3, ROGUE-4, ROGUE-5, ROGUE-6, ROGUE-7, ROGUE-8, ROGUE-9, ROGUE-10, ROGUE-11, ROGUE-12, ROGUE-13, ROGUE-14, ROGUE-15, ROGUE-16, ROGUE-17, ROGUE-18, ROGUE-19, ROGUE-20, ROGUE-21, ROG", "answers": ["Quantitative evaluation methods using ROUGE, Recall, Precision and F1.", "standard ROGUE metric, Recall, Precision and INLINEFORM0 scores for ROGUE-1,  INLINEFORM2 scores for ROGUE-2 and ROGUE-L"], "all_classes": null, "length": 4395}
{"pred": " The baseline methods are:\n\n- BIBREF0: A non-domain-adaptive baseline with softmax regression.\n- BIBREF1: A non-domain-adaptive baseline with adversarial training.\n- BIBREF2: A non-domain-adaptive baseline with adversarial training and feature adaptation.\n- BIBREF3: A non-domain-adaptive baseline with adversarial training and feature adaptation.\n- BIBREF4: A non-domain-adaptive baseline with adversarial training and feature adaptation.\n- BIBREF5: A non-domain-adaptive baseline with adversarial", "answers": ["(1) Naive, (2) mSDA BIBREF7, (3) NaiveNN, (4) AuxNN BIBREF4, (5) ADAN BIBREF16, (6) MMD", "non-domain-adaptive baseline with bag-of-words representations and SVM classifier, mSDA, non-domain-adaptive CNN trained on source domain, neural model that exploits auxiliary tasks, adversarial training to reduce representation difference between domains, variants of deep CNNs are used for encoding images and the MMDs of multiple layers are jointly minimized"], "all_classes": null, "length": 5063}
{"pred": " Their system's absolute accuracy is not provided in the article.", "answers": ["59.4% on wikipedia dataset, 93.4% on peer-reviewed archive AI papers, 77.1%  on peer-reviewed archive Computation and Language papers, and 79.9% on peer-reviewed archive Machine Learning papers"], "all_classes": null, "length": 4203}
{"pred": " The paper explores various distributional similarity measures and second-order vector approaches.", "answers": ["Skip–gram, CBOW", "integrated vector-res, vector-faith, Skip–gram, CBOW"], "all_classes": null, "length": 4259}
{"pred": " The two large-scale datasets used are the US and Italian datasets.", "answers": ["US dataset, Italian dataset", "US dataset, Italian dataset"], "all_classes": null, "length": 4857}
{"pred": " Profile changes vary for influential leads and their followers over the social movement.", "answers": ["Influential leaders are more likely to change their profile attributes than their followers; the leaders do not change their usernames, while their followers change their usernames a lot; the leaders  tend to make new changes related to previous attribute values, while the followers make comparatively less related changes to previous attribute values."], "all_classes": null, "length": 5092}
{"pred": " They show that there is space for further improvement by training a model on a larger dataset.", "answers": [" by testing humans on a random subset of 50 named entity and 50 common noun validation questions that the psr ensemble could not answer correctly", "majority of questions that our system could not answer so far are in fact answerable"], "all_classes": null, "length": 4232}
{"pred": " The metrics used in evaluation are BLEU, F1, and F2.", "answers": ["precision, recall , F1 score"], "all_classes": null, "length": 4515}
{"pred": " No, they report results on both English and Arabic data.", "answers": ["Unanswerable", "Yes"], "all_classes": null, "length": 7251}
{"pred": " The article does not provide information on the size of their data set.", "answers": ["a sample of  29,794 wikipedia articles and 2,794 arXiv papers "], "all_classes": null, "length": 4187}
{"pred": " Yes, they recommend translating the premise and hypothesis together.", "answers": ["No", "No"], "all_classes": null, "length": 4071}
{"pred": " No answer", "answers": ["Coverage, Avg. MCC and avg. +ve F1 score", "strategy formulation ability, we introduce a measure called Coverage( INLINEFORM0 ), To evaluate the predictive performance, we use Avg. MCC and avg. +ve F1 score"], "all_classes": null, "length": 5869}
{"pred": " They use a combination of computational approaches, human-based approaches, and qualitative methods.", "answers": ["Domain experts and fellow researchers can provide feedback on questions and help with dynamically revising them., connect to multiple disciplines, dual use", "Modeling considerations:  the variables (both predictors and outcomes)  are rarely simply binary or categorical;  using a particular classification scheme means deciding which variations are visible,; Supervised and unsupervised learning are the most common approaches to learning from data;  the unit of text that we are labeling (or annotating, or coding), either automatic or manual, can sometimes be different than one's final unit of analysis."], "all_classes": null, "length": 8530}
{"pred": " Reddit", "answers": ["Unanswerable"], "all_classes": null, "length": 8508}
{"pred": " The best performance was achieved by the HealthCare sector.", "answers": ["Energy with accuracy of 0.538", "Energy"], "all_classes": null, "length": 10349}
{"pred": " They have a background in linguistics, computational linguistics, computational text analysis, and AI.", "answers": ["Unanswerable"], "all_classes": null, "length": 8506}
{"pred": " Machine learning methods used in experiments include SVM, SVM-RBF, SVM-RBF-L1, SVM-RBF-L2, SVM-RBF-L1-L2, SVM-RBF-L1-L2-L3, SVM-RBF-L1-L2-L3-L4, SVM-RBF-L1-L2-L3-L4-L5, SVM-RBF-L1-L2-L3-L4-L5-L6, SVM-RBF-L1-L2-L3", "answers": ["Structural Support Vector Machine", "SVMhmm "], "all_classes": null, "length": 14468}
{"pred": " No", "answers": ["Yes", "Yes"], "all_classes": null, "length": 12950}
{"pred": " The state of the art described in the paper is a hybrid conceptual architecture and its implementation.", "answers": ["ELIZA,  PARRY, A.L.I.C.E., Cleverbot"], "all_classes": null, "length": 13395}
{"pred": " They use the UN's General Assembly records and speeches.", "answers": ["corpus of state speeches delivered during the annual UN General Debate", "corpus of state speeches delivered during the annual UN General Debate"], "all_classes": null, "length": 8647}
{"pred": " Doc2Vec, LDA", "answers": ["Document to Vector (Doc2Vec)", "Doc2Vec, PV-DBOW model"], "all_classes": null, "length": 8196}
{"pred": " Argument components that the ML methods aim to identify include micro-level argumentation structures like premise, rebuttal, and backing, as well as non-argumentative text.", "answers": ["claim, premise, backing, rebuttal, and refutation", "claim, premise, backing, rebuttal, refutation"], "all_classes": null, "length": 14472}
{"pred": " Yes, they report results only on English data.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 14465}
{"pred": " None of the datasets mentioned in the article are used for the development of the chatbots.", "answers": ["Custom dataset with user questions; set of documents, twitter posts and news articles, all related to finance.", "a self-collected financial intents dataset in Portuguese"], "all_classes": null, "length": 13401}
{"pred": " Yes, they analyze specific derogatory words, such as \"homosexual\" and \"gay\" in the context of media discourse about marginalized groups.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 12952}
{"pred": " A node in the network approach represents a state.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 8641}
{"pred": " The new corpus is sourced from a variety of domains across various registers of user-generated content, such as comments to articles, blog posts, as well as professional newswire articles.", "answers": ["user comments to newswire articles or to blog posts, forum posts, blog posts, newswire articles", "refer to each article, blog post, comment, or forum posts as a document"], "all_classes": null, "length": 14481}
{"pred": " They identify discussions of LGBTQ people in the New York Times by analyzing linguistic signals such as negative evaluations of a target group, essentialist thinking, and denial of agency.", "answers": ["act paragraphs containing any word from a predetermined list of LGTBQ terms "], "all_classes": null, "length": 12970}
{"pred": " Yes", "answers": ["No", "No"], "all_classes": null, "length": 8509}
{"pred": " Unanswerable", "answers": ["identifying the questions we wish to explore, Can text analysis provide a new perspective on a “big question” that has been attracting interest for years?, How can we explain what we observe?, hope to connect to multiple disciplines"], "all_classes": null, "length": 8555}
{"pred": " The article does not provide information about the evaluation metrics used.", "answers": ["precision, recall, F1 and accuracy", "Response time, resource consumption (memory, CPU, network bandwidth), precision, recall, F1, accuracy."], "all_classes": null, "length": 13391}
{"pred": " Yes", "answers": ["No", "Yes"], "all_classes": null, "length": 8643}
{"pred": " Different registers and domains pose challenges to this task. Analyzing the challenges and potential solutions for each register and domain is beyond the scope of this article. However, we can provide some general insights:\n\n- Register: Tone, context, and style can influence the task. For example, a debate between two parties can be more challenging than a debate between two individuals.\n- Domain: Different domains have different conventions and norms. For example, debates between politicians and pundits are different from debates between scientists.\n\nAnswer: The task is challenging across registers and domains.", "answers": ["linguistic variability"], "all_classes": null, "length": 14469}
{"pred": " The datasets were annotated using the Multi-SimLex protocol, which involves creating a shared evaluation benchmark for cross-lingual semantic similarity. The protocols for creating the datasets and evaluating the similarity judgments are described in detail in the article.", "answers": ["1. Each annotator must assign an integer score between 0 and 6 (inclusive) indicating how semantically similar the two words in a given pair are. A score of 6 indicates very high similarity (i.e., perfect synonymy), while zero indicates no similarity., 2. Each annotator must score the entire set of 1,888 pairs in the dataset.,  able to use external sources (e.g. dictionaries, thesauri, WordNet) if required, not able to communicate with each other during the annotation process"], "all_classes": null, "length": 14722}
{"pred": " Argumentation phenomena encountered in actual data are now accounted for by this work are:\n\n1. Argumentation models based on argumentation theory\n2. Argumentation on the Web\n3. Argumentation on the Web\n4. Argumentation on the Web\n5. Argumentation on the Web\n6. Argumentation on the Web\n7. Argumentation on the Web\n8. Argumentation on the Web\n9. Argumentation on the Web\n10. Argumentation on the Web\n11. Argumentation on the Web\n12. Argumentation on the Web\n13. Argumentation on the Web\n14. Argument", "answers": ["Unanswerable"], "all_classes": null, "length": 14471}
{"pred": " The 12 languages covered are English, Spanish, French, German, Italian, Portuguese, Russian, Romanian, Polish, Czech, Hungarian, and Turkish.", "answers": ["Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese", "Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese"], "all_classes": null, "length": 14660}
